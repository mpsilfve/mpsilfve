\chapter{Morphology and Morphological Tagging}
\label{chap:morphology}

This Chapter introduces the field of linguistic morphology and
morphological tagging. It will also present an overview of the current
state-of-the-art in morphological tagging.

\section{Morphology}
%\begin{itemize}
%\item The morphological system.
%\item Word, morpheme, lemma, stem.
%\item Word classes.
%\item Inflectional categories.
%\end{itemize}

\paragraph{Words} Words are the most readily accepted linguistic units
at least in Western written language. I define a word as a sequence of
letters, and possible numbers, which is surrounded by white-space or
punctuation. Matters are more complex in spoken language, written
languages that do not use white space (such as Chinese), and sign
language. Still, this definition covers most cases of interest from
the point of view of the field of morphological tagging.

\paragraph{Morphemes} Morphology is the sub-field of linguistics that
studies the internal structure of words. According to \cite{Bybee85},
morphology has traditionally been concerned with charting the {\it
  morpheme inventory} of language. That is, finding the minimal
semantic units of language and grouping them into classes according to
behavior and meaning. For example, the English word form ``dogs''
consists of two morphemes ``dog'' and ``-s''. The first one being a
{\it word stem} and the second one being an {\it inflectional affix}
marking plural number.

\paragraph{(Non-)Concatenative Morphology} In many languages, such as
English, words are mainly constructed by concatenating morphemes. For
example,``dog'' and ``-s'' can be joined to give the plural
``dogs''. This is called {\it concatenative morphology}. There are
many phenomena that fall beyond the scope of concatenative
morphology. For example, English plural number can be signaled by
other, less transparent, means as demonstrated by the word pairs
``m{\bf ou}se/m{\bf i}ce'' and ``m{\bf a}n/m{\bf e}n''. In these
examples, choice of vowel indicates number. This type of inflection is
called {\it ablaut}. In general, phenomena that fall beyond the scope
of simple concatenation are called {\it non-concatenative}.

Cross-linguistically, the most common form of non-concatenative
morphology is {\it suppletion}. Suppletion is the irregular
relationship between word forms examplified by the English infinitive
verb ``go'' and its past tense ``went''. Such irregularity occurs in
all languages. Even though suppletion is cross-linguistically common,
most lexemes in a language naturally adhere to regular inflection
patterns. For example, most English verbs form a past tense by
adjoining the suffix ``-ed'' onto the verb stem.

Morphophonological alternations are a further example of
non-concatenative morphology. These are sound changes that occur at
morpheme boundaries. A cross-linguistically common example is nasal
assimilation \citep[p. 29]{Carr1993}, where the place of articulation
of a nasal depends on the following stop. As an example, consider the
English prefix ``in-''. The ``n'' in ``input'' and ``inset'' is
pronounced as ``m'' and ``n'', respectively.

Languages differ with regard to the amount of non-concatenative
morphology. Some, like Turkish, employ almost exclusively
concatenation.  Others, such as English, employ a mix of concatenation
and non-concatenative phenomena. Still, concatenative morphology is
probably found to some degree in all languages. It is especially
prevalent in languages with rich morphology, such as Finnish or
Turkish. From the point of view of language technology for
morphologically rich languages, it is therefore of paramount
importance to be able to handle concatenative morphology.

\paragraph{Morphotax} Stems in English can often occur on their own as
words and are therefore called {\it free morphemes}. Inflectional
affixes cannot. Therefore, they are called {\it bound morphemes}. Such
rules belong to {\it morphotax}: the sub-field of morphology
concerned with defining the rules that govern the concatenative
morphology of a language. For example, ``dog'' and ``dog+s'' are valid
from the point of view of English morphotax whereas ``dogdog'' and
``s'' (in the meaning plural number) are not.

\paragraph{Word Class} The word forms ``dogs'' and ``cats'' share a
common number marker ``-s'' but they have different stems. Still, there
is a relation between the stems ``dog'' and ``cat'' because they can
occur with similar inflectional affixes and in similar sentence
contexts. Therefore, they can be grouped into a common {\it word
  class} or {\it part-of-speech}, namely nouns.  The inventory of word
classes in a language cannot be determined solely based on word
internal examination. Instead, one has to combine knowledge about the
structure of words with knowledge about interaction of the words in
sentences. The concept of word class, therefore, resides somewhere
between the linguistic disciplines morphology and {\it syntax} which
is the study of combination of words into larger units: phrases and
sentences.

\paragraph{Lexeme and Lemma} Word forms such as ``dog'' ``dogs'' and
``dog's'' share a common stem ``dog''. Each of the word forms refers
to the concept of {\sc dog}, however, different forms of the word are
required depending on context. Different word forms, that denote the
same concept, belong to the same {\it lexeme}. Each lexeme has a {\it
  lemma} which is a designated word form representing the entire
lexeme. In the case of English nouns, the lemma is simply the singular
form, for example ``dog''. In the case of English verbs, the
infinitive, for example ``to run'', is usually used. The particular
choice depends on linguistic tradition. 

Lemmas are important for language technology because dictionaries and
word lists, which can be used to derive information about lexemes,
usually contain lemmas. Therefore, it is useful to be able to {\it
  lemmatize} a word form, that is produce the lemma given a word form.

\paragraph{Categories of Bound Morphemes} Whereas free morphemes are
grouped into word classes, bound morphemes are grouped into their own
categories according to meaning and co-occurrence restrictions. For
example, Finnish nouns can take a plural number
marker. Additionally, they can take one case marker from an inventory
of $15$ possible case markers, one possessive suffix from an inventory
of $6$ possible markers and a number of clitic affixes
\citep{Hakulinen2004}. The categories of bound morphemes usually
belong to particular word classes, however, several word classes may
share a particular class of bound morphemes. For example, both
adjectives and nouns take a number in English.

\paragraph{Morphological analysis} In many applications such as
information retrieval systems and syntactic parsers, it is useful to
be able to provide an exhaustive description of the morphological
information associated with a word form. Such a description is called
a {\it morphological analysis} or {\it morphological label} of the word
form. For example, the English word form ``dogs'' could have a
morphological analysis ``dog+Noun+Plural''. The granularity and
appearance of the morphological analysis depends on linguistic
tradition and the linguistic theory which is being applied, however,
the key elements are the lemma of the word form as well as a list of
the bound morphemes associated to the word form.

\section{Morphological Analyzers}
Word forms in natural languages can be ambiguous. For example, the
English ``dogs'' is both a plural form of a noun and the present third
person singular form of a verb. The degree of ambiguity varies between
languages. To some degree, it is also a function of the morphological
description: a coarse morphological description results in less
ambiguity than a finer one. A {\it morphological analyzer} is a system
which processes word forms and returns the complete set of possible
morphological analyses for each word form.

\paragraph{Applications} Morphological analyzers are useful both when
the lemma of the word is important and when the information about
bound morphemes is required. The lemma is useful in tasks where the
semantics of the word form is of great importance. These task include
information extraction and topic modeling. In contrast, bound
morphemes predominantly convey structural information instead of semantic
information. Therefore, they are more important for syntactic parsing and
shallow parsing which aim at uncovering the structure of linguistic
utterances.

\paragraph{Motivation} The need for full scale morphological analyzers
has been contested. For example, \cite{Church2005} has argued that
practical applications can mostly ignore morphology and focus on
processing raw word forms instead of morphologically analyzed
words. This may be a valid approach for English and other languages
which mainly utilize syntactic means like word order to express
grammatical information, especially when large training corpora are
available. In these languages the number of word forms in relation to
lexemes tends to be low. For example, in the Penn Treebank of English
\cite{Marcus1993} spanning approximately 1 million words, three
distinct word forms occur which have the lemma ``dog'', namely
``dog'', ``dogs'' and ``dogged''. It can be argued that no specific
processing is required to process English word forms.

In contrast to English, many languages do utilize morphology
extensively. For example, although the Finnish FinnTreeBank corpus
\citep{Voutilainen2011} only spans approximately 160,000 words, there
are 14 distinct word forms which have the lemma ``koira'' (the Finnish
translation of ``a dog'').\footnote{If different compound words of
  ``koira'', such as ``saksanpaimenkoira'' (German Shepard) are
  considered, there are 23 forms of koira in the FinnTreeBank corpus.}
In total, the Penn Treebank contains some 49,000 distinct word forms
whereas the FinnTreeBank contains about 46,000 word forms even though
it is only 20\% of the size of the English corpus. These
considerations illustrate the need for morphological processing for
morphologically rich languages like Finnish which make extensive use
of inflective morphology. Methods which rely purely on word forms will
simply suffer too badly from data sparsity. The experiments presented
in Chapter \ref{chapter:finnpos} show that a morphological tagger is
vital for morphological tagging of Finnish.

\paragraph{Variants} There are different types of morphological analysis
systems. The first systems used for English information retrieval were
{\it stemmers}, the most famous system being the Porter stemmer
\citep{Porter1997}. It uses a collection of rules which strip suffixes
from word forms. For example, ``connect'', ``connection'' and
``connected'' would all receive the stem ``connect''. The system does
not rely on a fixed vocabulary and can thus be applied to arbitrary
English word forms. The Porter stemmer, and stemmers in general, are
sufficient for information retrieval in English but they fall short
when more elaborate morphological information is required, for
example, in parsing. Moreover, they are too simplistic for
morphologically complex languages like Finnish and
Turkish.\footnote{However, they may suffice in some
  domains. \cite{Kettunen2005} show that a more elaborate stemmer,
  which can give several stem candidates for a word form, can perform
  comparable to a full morphological analyzer) in information
  retrieval}

{\it Morphological segmentation software}, such as Morfessor
\citep{Creutz2002}, are another type of morphological analyzers often
utilized in speech recognition for languages with rich morphology. The
Morfessor system splits word forms into a sequence of morphemelike
sub-strings. For example, the word form ``dogs'' could be split into
``dog'' and ``-s''.  This type of morphological segmentation is useful
in a wide variety of language technological applications, however it
is more ambiguous than a traditional morphological analysis where the
bound morphemes are represented by linguistic labels such as
plural. Moreover, Morfessor output does not contain information about
morphological categories that are not overtly marked. For example, in
Finnish, the singular number of nouns is not overtly marked (only
plural number is marked by an affix ``-i-''). Although not overtly
marked, such information can very useful for further processing.

The current state-of-the-art for morphological analysis of
morphologically complex languages are {\it finite-state morphological
  analyzers} \citep{Kaplan1994,Koskenniemi1984}. Full scale
finite-state analyzers can return the full set of analyses for word
forms. They can model morphotax and morphophonological alternations
using finite-state rules and a finite-state lexicon
\citep{Beesley2003}. In contrast to stemmers, which are quite simple,
and segmentation systems like Morfessor which can be trained in an
unsupervised manner, full-scale morphological analyzers typically
require a lot of manual work. The most labor intensive part of the
process is the accumulation of the lexicon.

Although, full-scale morphological analyzers require a lot of manual
work, the information they produce is very reliable. Coverage is a
slight problem because lemmas typically need to be manually added to
the system before word forms of that lemma can be analyzed. However,
morphological guessers can constructed from morphological analyzers
\cite{Linden2009}. These extend the analyzer to previously unseen
words based on similar words that are known to the analyzer.

The morphological analyzer employed by the work presented in this
thesis is the Finnish Open-Source Morphology (OMorFi)
\citep{Pirinen2011}. It is a morphological analyzer of Finnish
implemented using the open-source finite-state toolkit HFST
\cite{Linden2009hfst} and is utilized for the experiments presented in
Chapter \ref{chapter:finnpos}.
 
\section{Morphological Tagging and Disambiguation}
I define morphological tagging as the task of assigning each word in a
sentence a unique morphological analysis consisting of a lemma and a
morphological label which specifies the part-of-speech of the word
form and the categories of its bound morphemes. This contrasts with
POS tagging, where the task is to provide a coarse morphological
description of each words, typically the part-of-speech.

One interesting aspect of the morphological tagging task is that both
the set of potential inputs, that is sentences, and potential outputs,
that is sequences of analyses, are unfathomably large. Since each word
in a sentence $x = x_1,\ ...,\ x_T$ of length $T$ receives one label,
the complete sentence has $n^T$ possible label sequences $y = y_1,\
...,\ y_T$ when there are $n$ possible labels for an individual word. Given a
sentence of $40$ words and a label set of $50$ labels, the number of
possible label sequence is thus $40^{50} \approx 10^{80}$ which according
to Wolfram Alpha\footnote{{\tt{\url
      http://www.wolframalpha.com/input/?i=number+of+atoms+in+the+universe}}}
is the estimated number of atoms in the observable universe.

The exact number of potential English sentences of any given length,
say ten, is difficult to estimate because all strings of words are not
valid sentences.\footnote{Moreover, it is not easy to say how many
  word types the English language includes.} However, it is safe to
say that it is very large -- indeed much larger than the combined
number of sentences in POS annotated English language corpora
humankind will ever produce. Direct estimation of the conditional
distributions $p(y\cond x)$, for POS label sequences $y$ and sentences
$x$, by counting is therefore impossible.

Because the POS labels of words in a sentence depend on each other,
predicting the label $y_t$ for each position $t$ separately is not an
optimal solution. Consider the sentence ``The police dog me constantly although I
haven't done anything wrong!''. The labels of the adjacent words
``police'', ``dog'', ``me'' and ``constantly'' help to disambiguate
each other. A priori, we think that ``dog'' is a noun since the verb
``dog'' is quite rare. This hypothesis is supported by the preceding
word ``police'' because ``police dog'' is an established noun--noun
collocation. However, the next word ``me'' can only be a pronoun,
which brings this interpretation into question. The fourth word
``constantly'' is an adverb, which provides additional evidence
against a noun interpretation of ``dog''. In total, the evidence
points toward a verb interpretation for ``dog''.

The disambiguation of the POS label for ``dog'' utilizes both so
called {\it unstructured} and {\it structured} information. The
information that ``dog'' is usually a noun is
unstructured information, because it only refers to the POS label (the
prediction) of the word ``dog''. The information that verbs are much
more likely to be followed by pronouns than nouns is a piece of
structured information because it refers to the combination of several
POS labels. Both kinds of information are very useful, but a model
which predicts the label $y_t$ for each position in isolation cannot
utilize structured information.

Even though structured information is quite useful, this usefulness
has limits. For example the labels of ``dog'' and ``anything'' in the
example are not especially helpful for disambiguating each other. It
is a sensible assumption that the further apart two words are situated
in the sentence, the less likely it is that they can significantly aid
in disambiguating each other. However, this does not mean that the
interpretations of words that are far apart cannot depend on each
other -- in fact they frequently do. For example, embedded clauses and
co-ordination can introduce long range dependencies inside
sentences. Sometimes, even words in another sentence may help in
disambiguation. It is, however, difficult to utilize this information
in a tagger because most words that lie far apart are useless for
disambiguating each others morphological labels, which makes
estimation of statistics from data quite difficult.

Traditionally, morphological taggers have been classified into two
categories: {\it data-driven} and {\it rule-based}. Data-driven
taggers primarily utilize morphologically labeled training data for
learning a {\it model} that represents the relationship between text
and morphological labels. The model is typically based on very simple
facts called {\it features} that can be extracted from labeled
text. For example {\bf the second word in the sentence is ``dog'' and
  its label is noun+sg+nom} and {\bf the second word has label
  noun+sg+nom and the third word has label verb+pres+3sg}. Each
feature corresponds to a weight which determines its relative
importance and reliability. During training, these weights are
optimized to describe the relationship between sentences and label
sequences as closely as possible. Given an unlabeled input sentence,
it is possible to find the label sequence that the model deems most
likely. Thus the model can be used for tagging.

In contrast to data-driven systems, rule-based, or {\it
  expert-driven}, taggers do not primarily rely on training
data. Instead they utilize information provided by domain experts
(linguists in this case) using some rule formalism. These rules are
assembled into a grammar and compiled into instructions that can be
interpreted by a computer. In contrast to the weighted features in
data-driven systems, the rules in expert-driven systems are typically
categorical, that is they either apply or do not apply. 

The division into data-driven and expert-driven systems is not
clear-cut. For example, data-driven statistical taggers often employ a
morphological analyzer which is typically a rule-based
system. Conversely, rule-based systems can utilize statistics to solve
ambiguities which cannot be resolved solely based on grammatical
information. As seen below, it is also possible to integrate a
rule-based and data-driven approach more deeply into a {\it hybrid
  tagger}.

The Brill tagger \citep{Brill1992} is one of the early successes in
POS tagging. It is in fact a hybrid tagger. The tagger first labels
data using a simple statistical model (a unigram model of the
distribution of tags for each word form). It then corrects errors
introduced by the simple statistical model using rules that can be
learned from data or specified by linguists. Several layers of rules
can be used. Each layer corrects errors of the previous
layer. Although the Brill tagger is an early system, it might still be
quite competitive as shown by \cite{Horsmann2015}, who compared a
number of POS taggers for English and German on texts in various
domains (these experiments included state-of-the-art models such as
the averaged perceptron). According to their experiments, the Brill
tagger was both the fastest and most accurate.

One of the major successes of the rule-based paradigm is the
Constraint Grammar formalism \citep{Karlsson1995}. The formalism uses
finite-state disambiguation rules to disambiguate the set of
morphological labels given by a morphological analyzer. The approach
may still produce the most accurate taggers for English.
\cite{Voutilainen1995} cite an accuracy of 99.3\% on English. Direct
comparison of tagging systems based on accuracies reported in
publications is, however, difficult because they are trained on
different data sets and use different morphological label inventories
but experiments conducted by \cite{Samuelsson1997} show that
constraint grammar performed better than a state-of-the-art
data-driven tagger at the time.

Although, there are many highly successful and interesting rule-based
and hybrid systems, my main focus is data-driven morphological
tagging. The first influential systems by \cite{Church1988} and
\cite{DeRose1988} were based on Hidden Markov Models (HMM) which are
presented in detail in Chapter \ref{chapter:hmm}. These early
data-driven systems achieved accuracy in excess of 95\% when tested on
the Brown corpus \citep{Francis1964}. Later work by \cite{Brants2000}
and \cite{Halacsy2007} refined the approach and achieved accuracies in
the vicinity of $96.5\%$. Publications \ref{pub:1} and
\ref{pub:2} continue this work. They set up the tagger as a
finite-state system and experiment with different structured models
for the HMM tagger.

HMM taggers are so called generative statistical models. They specify
a probabilistic distribution $p(x,y)$ over sentences $x$ and label
sequences $y$. In other words, these systems have to model both
sentences and label sequences at the same time. Unfortunately, this is
very difficult without making simplistic assumptions about the labeled
data. For example, a standard assumption is that the probability of a
word is determined solely based on its morphological label. This
assumption is obviously incorrect as demonstrated by word
collocations. %In practice, such independence assumptions rule out many
%useful tagger features such as word collocations.

In order to be able to use more sophisticated features to describe the
relation between the input sentence and its morphological labels,
\cite{Ratnaparkhi1997} used a discriminative classification model
instead of a generative one. Whereas, a generative model represents a
joint probability $p(x,y)$ for a sentence and label sequence, a
discriminative model only represents the conditional probability
$p(y|x)$ of label sequence $y$ given sentence $x$. This means that the
sentence $x$ no longer needs to be modeled. Therefore, more elaborate
features can be used to describe the relation between sentences and
morphological labels. The model still has to account for the internal
structure of $y$ but because $y$ can be anchored much more closely to
the input sentence, the accurate modeling of relations between the
individual labels in $y$ is not as important in a discriminative
tagger.\footnote{This is illustrated by the fact that an unstructured
  discriminative model which does not model relations between labels
  at all fares almost as well on tagging the Penn Treebank as a
  structured model when the taggers use the same unstructured
  features. According to experiments performed by the author on the
  Penn Treebank the difference in accuracy can be as small as
  0.4\%-points (a drop from 97.1\% to 96.7\%). Dropping the structured
  features from a typical HMM tagger reduces performance substantially
  more.}

The Maximum Entropy Markov Model (MEMM) used by \cite{Ratnaparkhi1997} is a
structured model but it is trained in an unstructured fashion. For
each training sentence $x = (x_1,\ ...,\ x_T)$ and its label sequence
$y = (y_1,\ ...,\ y_T)$ the model is trained to maximize the
probability $p(y_t| x,\ y_1,\ ...,\ y_{t - 1})$
in each position $t$. This means that the model relies on correct
label context during training time. This causes the so called {\it
  label bias problem} described by \cite{Lafferty2001}. Essentially,
label bias happens because the model relies too much on label
context. Another form of bias, namely observation bias investigated by
\cite{Klein2002} may in fact be more influential for POS tagging and
morphological tagging. These biases seem to have a real impact on
tagging accuracy. In fact, \cite{Brants2000} showed that it is
possible for a well constructed generative tagger to outperform a MEMM
tagger, although direct comparison is difficult because the test and
training sets used by Ratnaparkhi and Brants differ. Additional
support for the superiority of the HMM model, is however provided by
\cite{Lafferty2001} whose experiments indicate that the performance of
the MEMM is inferior to the HMM on simulated data when using the same
set of features.

\cite{Lafferty2001} proposed Conditional Random Fields (CRF) as a
solution to the label bias problem. The CRF is trained in a structured
manner (it is a so called globally normalized model) and does not
suffer from label or observation bias. According to their experiments,
the CRF model outperforms both the HMM and MEMM in classification on
randomly generated data and POS tagging of English when using the same
feature sets. Moreover, the CRF can employ a rich set of features like
the MEMM which further improves its accuracy with regard to the HMM
model.

Another discriminative model, the averaged perceptron tagger, is
proposed by \cite{Collins2002}. The model is a
structured extension of the classical perceptron
\citep{Rosenblatt1958}. The main advantage of the perceptron tagger
compared to the CRF model is that it is computationally more efficient
and also produces sparser models.\footnote{Although, different
  regularization methods can give sparse models also for the CRF.} Its
training procedure is also amenable to a number of optimizations like
beam search. These are explored in Chapter \ref{chapter:crf}. The main
drawback is that, while the classification performance of the CRF and
averaged perceptron tagger is approximately the same\footnote{For
  example experiments performed by \cite{Nguyen2007} indicate that the
  classification performance of the averaged perceptron algorithm can
  in fact be better than the performance of the Conditional Random
  field.}, the averaged perceptron tagger is optimized only with
regard to classification. It does not give a reliable distribution of
alternative morphological tags which can sometimes be useful in
downstream applications like syntactic parsers. Nevertheless, the
averaged perceptron tagger and its extensions, like the margin infused
relaxed algorithm (MIRA) \cite{Taskar2003} and the closely related
structured Support Vector Machine (SVM) \citep{Tsochantaridis2005},
are extensively applied in sequence labeling tasks such as POS
tagging.

The CRF, averaged perceptron, SVM and other related classifiers can be
seen as alternative estimators for hidden Markov models (a terminology
used by for example \cite{Collins2002}) or linear classifiers. For
example Publication \ref{pub:4} and \cite{Nguyen2007} explore different
estimators for linear classifiers and compare them.

While these models have been extensively investigate for POS tagging,
the focus of this thesis is morphological tagging. Generative taggers
such as the HMM have been applied to morphological tagging by for
example \cite{Halacsy2007} and Publication \ref{pub:2} but as in the
case of English, generative models cannot compete with discriminative
models with regard to accuracy.

Morphological tagging using discriminative taggers has been
investigated by \cite{Chrupala2008} who use a MEMM and
\cite{Spoustova2009} who utilize an averaged perceptron
tagger. However, these works do not adequately solve the problem of
slow training times for morphological taggers in the presence of large
label sets. \cite{Spoustova2009} use a morphological analyzer to limit
label candidates during training. This is a plausible approach when a
morphological analyzer is available and when its coverage is quite
high. This, however, is not always the case. Moreover, %as the
%experiments presented in Chapter \ref{chapter:finnpos} indicate, 
using only the candidates emitted by an analyzer during training can
degrade classification performance. Publication \ref{pub:6} and the
experiments in Chapter \ref{chapter:finnpos} present alternative
methods for accelerating model estimation using a cascaded model
architecture.

The structure present in large morphological label sets can be
leveraged to improve tagging accuracy. For example, it is possible to
estimate statistics for sub-labels, such as ``noun'', of complex
labels ``noun+sg+nom''. This approach is explored by for example
\cite{Spoustova2009} who extract linguistically motivated sub-label
features. Publication \ref{pub:5} further investigate this approach and
shows that general unstructured and structured sub-label features lead
to substantial improvement in accuracy. Additional experiments are
reported in Chapter \ref{chapter:finnpos}.

Recently, \cite{Muller2013} applied a cascaded variant of the CRF
model to morphological tagging of several languages in order to both
speed up training and combat data sparsity. Publications \ref{pub:5} and
\ref{pub:6} continue this line of research by setting up a
cascade of a perceptron classifier and a generative classifier used
for pruning label candidates. This combination delivers competitive
results compared to the cascaded CRF approach as demonstrated by
Publication \ref{pub:6} while also delivering faster training times.

Morphological tagging can be done concurrently with parsing.
\cite{Bohnet2013} present experiments on the Turku Dependency Treebank
also used in Publication \ref{pub:6}. Although, the data splits are
different, it seems that the tagging results obtained in Publication
\ref{pub:6} are still better than the results of joint tagging and
parsing.

Morphological tagging includes the task of
lemmatization. \cite{Chrupala2008} sets up this task as a
classification task as explained in Chapter
\ref{chapter:lemmatization} and Publication \ref{pub:6} mostly follows
this approach. \cite{Muller2015} explore joint tagging and
lemmatization and shows that this improves both tagging and
lemmatization results. Although, it would be very interesting to
experiment with joint tagging and lemmatization, it remains future
work for the author. 

Data-driven classifiers can also be used for morphological
disambiguation and, as the experiments in Chapter
\ref{chapter:finnpos} demonstrate, the combination of a morphological
analyzer and discriminative tagger performs substantially better than
a purely data-driven morphological tagger. There are two principal
approaches to data-driven morphological disambiguation. Firstly, the
analyzer can simply be used to limit label candidates. For example,
for English, the word ``dog'' could receive a verb label and a noun
label but not a determiner label. The second approach is to use the
morphological analyzer in feature extraction. In discriminative
taggers, the labels and label sets given by the morphological analyzer
can be directly used as features.

This thesis will mainly be concerned with a data-driven supervised
learning setting but semi-supervised systems and hybird systems that
combine data-driven and linguist dirven methods have also been
investigated in the field. \cite{Spoustova2009} and \cite{Sogaard2011}
apply self-training where a large amount of unlabeled text is first
tagged and then used to train a tagger model in combination with hand
annotated training data. This leads to significant improvements for
English and Chzech. \cite{Spoustova2009} additionally uses a voting
scheme where different taggers are combined for improved
accuracy. This remains future work for the author.

\cite{Hulden2012} investigate various combinations of HMM models and
constraint grammars for tagging. They show that a hybrid approach can
lead to improved tagging accuracy and also reduced rule development
time. A nearly identical setup was also explored by
\cite{Orosz2013}. A very similar setup was also used by
\cite{Spoustova2007} who examined combinations of hand-written rules
(very similar to constraint grammar rules) and an HMM, perceptron
tagger and a MEMM. While semi-supervised training and hybrid methods are very
interesting, they remain future work for the author at the present
time. %It can be argued that semi-supervised training does not differ
%much between morphologically complex languages and for example
%English.

%\begin{itemize}
%\item POS tagging vs. Morphological tagging.
%\item Statistical vs. rule-based.
%\item Is it a reasonable division?
%\item Influential rule based approaches: \cite{Brill1992}
%  \cite{Karlsson1995}.
%\item First successful HMM statistical approaches: \cite{Church1988}
%  \cite{DeRose1988}.
%\item Problem: A generative tagger has to model the input
%  sentences. This forces the use of simple local features.
%\item Solutions: Either try to model the input using a more elaborate
%  model which does not work \cite{Ruokolainen2013}.
%\item Better local features using a discriminative
%  approach\cite{Ratnaparkhi1997}.
%\item Still a well devised HMM model can surpass \cite{Brants2000},
%  \cite{Halacsy2007}.
%\item \cite{Silfverberg2010} and \cite{Silfverberg2010} implement HMM
%  taggers as finite-state systems.
%\item Label bias \cite{Lafferty2001} and observation bias \cite{Klein2002}.
%\item Solution: Conditional random fields \cite{Lafferty2001}.
%\item Another Solution: Support Vector Machines \cite{Cortes1995},
%  \cite{Gimenez2004}.
%\item A simple solution: Averaged perceptron taggers \cite{Collins2002}.
%\item These can be seen as alternative estimators for a discriminative
%  HMM tagger.
%\item \cite{Ruokolainen2014} examines several different approaches to
%  parameter estimation.
%\item Applications to morphological tagging: Marmot using a cascaded
%  model \cite{Muller2013} and Morfette \cite{Chrupala2008}.
%\item Joint Lemmatization and tagging \cite{Muller2015}.
%\item Tagging can also be combined with morphological segmentation
%  \cite{MullerX}.
%\item Using a morphological analyzer in different ways. 
%\item Morphological analyzer can be used as a tag dictionary during
%  decoding.
%\item \cite{Spoustova2009} use the morphological analyzer to restrict
 % label candidates during training but as experiments in Chapter
%  \ref{chapter:finnpos} show, this leads to reduced performance
%  because of too heavy pruning.
%\item \cite{Silfverberg2014} use sub-label features and
%  \cite{Silfverberg2015} combine them with a cascaded approach.
%\item \cite{Chrupala2008} and \cite{Silfverberg2015} adopt the same
%  approach to lemmatization although the particular features of the
%  lemmatizer differ.
%\item A hybrid approach of rules and statistics can also be used
%  \citep{Spoustova2007,Hulden2012,Orosz2013}
%\item Further improvement could gained by semi-supervised techniques
%  such as self-training \cite{Sogaard2011,Spoustova2009} and using
%  voting \cite{Spoustova2009}.
%\item This thesis will only examine the supervised learning setting
%  because voting and self-training do not really differ much between
%  English and a morphologically complex languages such as Finnish.
%\end{itemize}