\chapter{Machine Learning}
\label{chap:ml}

This section outlines the basic methodology followed in machine
learning research for NLP. I will briefly
discuss machine learning from a general point of view and then present
supervised machine learning in more detail using linear regression as
example.

\paragraph{Supervised and Unsupervised ML} There exists a broad
division of the field of machine learning into three sub-fields.\footnote{However, for example reinforcement learning and active learning may not fit easily into this classification.}
\begin{enumerate}
\item In {\it supervised} machine learning the aim is to learn a mapping
  from inputs $x$ (such as sentences) to outputs $y$ (such as
  morphological label sequences). To this aim, a supervised system
  uses training material consisting of input-output pairs $(x,y)$ and
  a model which can represent the mapping $x \mapsto y$. Training of
  the model consists of tuning its parameters in such a way that the
  model accurately describes mapping between the inputs and outputs in
  the training data. Typically, supervised machine learning is
  employed for tasks such as classification and regression. Examples
  in the field of natural language processing include POS tagging and
  other tasks that can be framed as labeling (for example named entity
  recognition), speech recognition and machine translation.
\item In contrast to supervised machine translation, {\it unsupervised}
  approaches exclusively utilize unannotated data, that is the
  training data consists solely of inputs $x$. Unsupervised machine
  learning is most often used for various kinds of clustering tasks
  where inputs are grouped into sets of similar examples. Therefore,
  it has applications for example in exploratory data analysis.
\item Finally, {\it semi-supervised}
  systems use an annotated training set in combination with a,
  typically, very large unannotated training set to improve the
  results beyond the maximum achievable by either approach in
  isolation.
\end{enumerate}

Unsupervised and Semi-supervised techniques have many applications in
the field of tagging. For example, distributional similarity can be
used to improve tagging accuracy for OOV words
\citep{Huang2009a,Ostling2013} and self-training can improve the
accuracy of a tagging system \citep{Spoustova2009,Sogaard2011}.  This
thesis, however, focuses exclusively on supervised learning.

\section{Supervised Learning}
%\begin{itemize}
%\item Example: linear regression.
%\item Estimation from a sample.
%\item Convexity, smoothness.
%\item Regularization.
%\item Methodology: Training, development and test sets. 
%\item Significance testing.
%\end{itemize}

In this section, I will illustrate the key concepts and techniques in
supervised machine learning using the very simple example of {\it
  linear regression}. I will explain the plain linear regression model
and show how it can be fitted using training data. I will then briefly
present {\it ridge regression} which is a {\it regularized} version of
linear regression.

I choose linear regression as example because it is a simple model yet
can be used to illustrate many important concepts in machine
learning. Moreover, the model has several tractable properties such as
smoothness and convexity. Additionally, it can be seen as the simplest
example of a linear classifier which is a category of models
encompassing conditional random fields, the hidden Markov model and
average perceptron classifier presented in later chapters.

\paragraph{Linear Regression} As a simple example, imagine a person
called Jill who is a real estate agent.\footnote{This example is
  inspired by the Machine learning course provided by Coursera and at
  the time taught by Andrew Ng.} She is interested in constructing an
application, for use by prospective clients, which would give rough
estimates for the selling price of a property. Jill knows that a large
number of factors affect housing prices. Still, there are a few very
robust predictors of price that are easy to measure.
She decides to base the model on the following predictors:
\begin{enumerate}
\item The living area.
\item The number of rooms.
\item The number of bathrooms.
\item Size of the yard.
\item Distance of the house from the city center.
\item Age of the house.
\item Elapsed time since the last major renovation.
\end{enumerate}

Jill decides to use the simplest model which seems reasonable. This
model is linear regression which models the dependent
  variable, the house price, as a linear combination of the independent
variables listed above and parameter values in $\R$. The linear
regression model is probably not accurate. It fails in several
regards. For example, increasing age of the house probably reduces the
price up to a point but very old houses can in fact be more expensive
then newly built houses especially if they have been renovated lately.
Although, the linear model is unlikely to be entirely accurate, Jill is
happy with it because the intention is just to give a ball park
estimate of the price for the prospective client.

To formalize the linear regression model, let us call the dependent
variable price $y$ and each of the independent variables living area,
number of rooms and so on $x_i$. Given a vector $x = (x_1\ ...\
x_n\ 1)^\top \in \R^{n+1}$, which combines the independent
variables $x_i$, a bias term $1$, and a parameter vector $\theta \in
\R^{n+1}$ the linear regression model is given by Equation
\ref{eq:linreg}.\footnote{In reality, each of the predictors would probably
  be transformed to give all of them the same average and
  variance. Although this ii not required in theory, it tends to give
  a better model.}

\begin{equation}
y(x\parcond \theta) = x^\top\theta\label{eq:linreg}
\end{equation}

Two questions immediately arise: How to compute the price given
parameters and predictors and how to compute the parameter vector
$\theta$. These questions are common for all supervised learning
problems also when using other models than the linear regression
model.

\paragraph{Inference} The first question concerns {\it inference},
that is finding finding the values of the dependent variable given
values for the independent variables. In the case of linear
regression, the answer to this question is straightforward. To compute
the price, simply perform the inner product in Equation
\ref{eq:linreg}. The question is, however, not entirely settled
because one might also ask for example how close to the actual price
the estimate $y$ is likely to be. A related question would be to
provide an upper and lower bound for the price so that the actual
price is very likely to be inside the provided bounds. To answer these
questions, one would have to model the expected error.

Inference is very easy and also efficient in the case of linear
regression. With more complex models such as structured graphical
models which are investigated in Chapters \ref{chapter:hmm} and
\ref{chapter:crf}, it can however be an algorithmically and
computationally challenging problem. The task is still the
same: Find the $y$ which is most likely given the input.

\paragraph{Training Data} The second question concerns {\it estimation
  of model parameters} and it is more complex than the question of
inference. First of all, Jill needs training data.  In the case of
house price prediction, Jill can simply use data about houses she has
brokered in the past. She decides to use a training data set
$\mathcal{D} = \{(x^1, y^1), ..., (x^T, y^T)\}$, where each $x^t =
(x^t_1\ ...\ x^t_n\ 1)$ is a vector of independent variable values
(living area, age of the house and so on) and $y^t$ is the dependent
variable value, that is the final selling price of the house. The last
element $1$ in $x^t$ is the bias which is constant. Now Jill needs to
make a choice. How many training examples $(x^t, y^t)$ does she need?
The common wisdom is that more data is always better. In practice, it
is a good idea to start with a small training data and increase the
number of training examples until the performance of the system
plateaus.

\paragraph{Data Sparsity} Whereas it is fairly easy to get a
sufficient amount of training data for our example which only has a
few parameters, it is vastly more difficult to accomplish with more
complicated models in natural language processing. When there is
insufficient data to estimate model parameters accurately, the data is
called sparse. One central question in this thesis is how to
counteract {\it data sparsity} in morphological tagging.

\paragraph{Loss Functions} The objective in estimation is to find a
parameter vector $\theta$ which in some sense minimizes the error of
the house price predictions $y(x^t\parcond \theta)$ when compared to
the actual realized house prices $y^t$ in the training data. The usual
minimization criterion used with linear regression is the least square
sum criterion given in Equation \ref{eq:lss}. It is minimized by a
parameter vector $\theta$ which gives as small square errors $|y^t -
y(x^t \parcond \theta)|^2$ as possible.

\begin{equation}
\theta = \argmin_{\theta' \in \R^n} \sum_{x^t \in \mathcal{D}} | y^t - y(x^t\parcond \theta')|^2\label{eq:lss}
\end{equation}

The square sum is an example of a {\it loss function} (also called the
objective function). A loss function assigns a non-negative real loss
for each parameter vector. Using the concept of loss function, the
objective of estimation can be reformulated: Find the parameter vector
$\theta$ that minimizes the average loss over the training data.

\paragraph{Iterative Estimation} In the case of linear regression
model, there is an exact solution for the optimization of parameter
vector $\theta$.\footnote{The solution is given by $\theta = X^+Y$
  where $X^+ = (X^\top X)^{-1}X^\top$ is the More-Pennrose
  pseudo-inverse of $X$.} This does not hold for more complex
models. Moreover, the exact solution might often not be the one that
is desired because it does not necessarily generalize well to unseen
examples. This is called {\it overitting}. Fortunately, the loss
function can be modified to counteract overfitting. After the
modification, the parameter optimization problem might, however, no
longer have a closed form solution.

Because the loss of the training data is a function of the model
parameters, one can apply mathematical analysis for finding optimal
parameter values. These methods include for example Newton's method
which is an iterative procedure that can be used to find the zeros of
a differentiable function or local extrema of a twice differentiable
function. Approximations of Newton's method, so called Quasi-Newton
methods \citep{Liu1989}, have also been developed because Newton's
method requires evaluation and inversion of the Hessian matrix of a
function. This is a very costly operation for functions where the
domain has high dimension. Quasi-Newton methods use approximations of
the inverse Hessian.

A simpler method called gradient descent can be applied to functions
that are once differentiable. In
general, gradient descent converges toward the optimum more slowly
than Newton's method, however, the computation of one step of the
iterative process is much faster when using gradient
descent. Therefore, it may be faster in practice.

All gradient based methods rely on differentiability of the loss
function.\footnote{At least, differentiability almost everywhere.} For
the models used in this thesis, differentiability holds. Gradient
based methods work in the following general manner. Let
$\mathcal{L}_{\mathcal{D}}:\R^n \rightarrow \R$ be the loss of the training data
$\mathcal{D}$.

\begin{enumerate}
\item Start at a random point $\theta_0$ in the parameter space.
\item Determine the direction of steepest descent of the loss
function. This is the negative gradient $-\nabla
\mathcal{L}_{\mathcal{D}}(\theta_t)$ at point $\theta_t$.\label{alg:dir}
\item Determine a suitable step size $\alpha_t \in \R_+$.
\item Take a step of length $\alpha_t$ in direction $v_t$ to get to
the next point in the parameter space $\theta_{t+1}$, that is
$\theta_{t+1} = \theta_t - \alpha_t \nabla \mathcal{L}_{\mathcal{D}}(\theta_t)$.
\item If the difference in loss $|\mathcal{L}_{\mathcal{D}}(\theta_{t+1}) -
\mathcal{L}_{\mathcal{D}}(\theta_t)|$ is smaller than a threshold $\rho$, set
$\theta = \theta_{t+1}$. Otherwise, set $\theta_t = \theta_{t+1}$ and
return to line \ref{alg:dir}.
\end{enumerate}

The main difference between first and second order methods is the
computation of the step size $\alpha_t$. Second order methods can take
longer steps when the loss is plateauing. Thus they typically take
fewer steps in total. In first order methods such as gradient descent,
$\alpha_t$ can be constant, a decreasing function of $t$ or can also
be determined by a line search in the direction of $-\nabla
\mathcal{L}_{\mathcal{D}}(\theta_t)$. For example $\alpha_t =
t^{-1}$ may work.%\footnote{In general, stepsize $(\alpha_t)_{t \in
%\N}$ that resemble the harmonic sequence, that is $\sum \alpha_t^2 <
%\infty$ and $\sum \alpha_t = \infty$, guarantee convergence of
%gradient descent to an minimum of the loss function (if it exists) for
%a wide variety of functions \cite{someone}}


As the meta-algorithm above suggests, gradient based optimization
algorithms are local in the sense that they always move in the
direction of steepest descent of the loss function, that is toward a
local optimum. Therefore, they will in general not find the global
optimum of the loss function. By choosing a {\it convex} loss
function, which has maximally one local, and thus also, global optimum it
is possible to avoid getting stuck at local optima.

Convexity is, however, not enough to guarantee convergence to a global
optimum. First of all, a global optimum might not exist.\footnote{This
can happen if the domain of the loss function is not
compact. Unfortunately, it usually is not.} Moreover, convergence may be
too slow. This can leads to premature termination of the training
procedure. This is specifically a problem for first order methods.

\paragraph{Online Estimation} The optimization methods
discussed up to this point have been so called {\it batch
  methods}. The derivatives of the loss function is computed over the
entire training data and parameters are updated accordingly. Batch
methods can be slow and subsequent training when new training examples
become available is computationally intensive. {\it Online algorithms}
are an alternative to batch methods, where the loss is instead
computed for a randomly chosen training example and the parameters are
then updated accordingly. In practice, online methods
can give fast convergence. Moreover, re-training is relatively
efficient when new training examples become available.

{\it Stochastic gradient descent} is a well known online estimation
algorithm. The algorithm processes one random training example at a
time. It uses the gradient $\nabla L_{\mathcal{D}[i]}(\theta)$ of the
loss for this training example $\mathcal{D}[i]$ to approximate the
gradient $\nabla L_{\mathcal{D}}(\theta)$ over the entire training
data $\mathcal{D}$. It is identical to the ordinary batch gradient
descent except that it is an online estimation algorithm. In practice,
SGD converges substantially faster than regular gradient descent
\citep{Vishwanathan2006} because the evaluation of the appoximate
gradient is very fast compared to evaluation of the gradient over the
entire training data.

%She also needs to
%decide upon an {\it estimator}, that is, a method for setting the
%parameters $\theta$.

\paragraph{Regularization} Due to the problem of over-fitting, a
family of heuristic techniques called {\it regularization} is often
employed. They aim to transform the original problem in a way which
will penalize both deviance from the gold standard and ``complexity''
of the solution $\theta$. Regularization can be seen to convey the
same idea as Occam's Maxim which states that a simpler explanation for
a phenomenon should be preferred when compared to a more complex
explanation yielding equivalent results. Of course, this does not
explain what is meant by a ``complex'' parameter vector
$\theta$.

To illustrate simple and complex parameter vectors, examine a case of
linear regression where the dependent variable $y$ and the predictors
$x_i$ have mean $0$ and variance $1$ in the training data. This may
seem restrictive but in fact any linear regression problem can easily
be transformed into this form by applying an affine transformation $z
\mapsto az - b$. When doing inference, this affine transformation can
simply be reversed by applying $z \mapsto a^{-1} (z + b)$. The
simplest parameter vector $\theta$ is clearly the zero vector $\theta
= (0 ... 0)$. It corresponds to the hypothesis that the
predictors $x_i$ have no effect on the dependent variable
$y$. According to this hypothesis, the prediction for the house price
is identically zero.

The zero solution to a linear regression problem is simple but also
completely biased. Because we are assuming that the independent
variables $x_i$ explain the dependent variable $y$, a model that
completely disregards them is unlikely to give a good fit to the
training data. By introducing a regularization term into the loss
function, we can however encourage simple solutions while at the same
time also preferring solutions that give a good fit. There are several
ways to accomplish this but the most commonly used are so called $L_1$
and $L_2$ regularization.\footnote{Another approach to counteracting
  overfitting is provided by Bayesian statistics where the parameter
  vector $\theta$ is drawn from a prior distribution. In practice,
  Bayesian methods and regularization are often equivalent.} These are
general regularization methods that are employed in many models in
machine learning.

The $L_1$ regularized loss function for linear regression is given in
Equation \ref{eq:lss-l1}. $L_1$ regularization, also called LASSO
regularization \cite{Tibshirani1996}, enforces solutions where many of
the parameter values are $0$ (such parameter vectors are called
sparse). It is suitable in the situation where the model is over
specified, that is, many of the predictors might not be necessary for
good prediction. The $L_1$ regularized linear regression loss is given
by Equation \ref{eq:lss-l1}.

\begin{equation}
\theta = \argmin_{\theta' \in \R^n} \sum_{x_t \in \mathcal{D}} | y^t - y(x^t\parcond \theta')|^2 + \lambda \sum_i |\theta_i|\label{eq:lss-l1}
\end{equation}

The $L_2$ regularized loss function is given in \ref{eq:lss-l2}. $L_2$
regularization is also called Tikhonov regularization. In contrast to
$L_1$ regularization, it directly prefers solutions with small norm. A
linear regression model with Tikhonov regularization is called a ridge
regression model.

\begin{equation}
\theta = \argmin_{\theta' \in \R^n} \sum_{x_t \in \mathcal{D}} | y_t - y(x_t\parcond \theta')|^2 + \lambda \|\theta\|^2 = \argmin_{\theta' \in \R^n} \sum_{x_t \in \mathcal{D}} | y_t - y(x_t\parcond \theta')|^2 + \lambda \sum_i |\theta[i]|^2\label{eq:lss-l2}
\end{equation}

The coefficient $\lambda \in \R^+$ is called the {\it
  regularizer}. The regularizer determines the degree to which model
fit and simplicity affect the loss. A higher $\lambda$ will increase
the loss for complex models more than a lower one. When $\lambda$
increases, the optimal parameter vector $\theta$ approaches the zero
vector and when it decreases $\theta$ approaches the parameters that
fit the training data as closely as possible. This is called
under-fitting.

\paragraph{Hyper-parameters} The regularizer is a so called {\it
  hyper-parameter} of the regularized liner regression model. It is
easy to see that increasing $\lambda$ will automatically increase the
loss. Therefore, there is no direct way to estimate its correct
magnitude simply using the training data. Instead {\it held-out data}
can be used. Held-out data is labeled data that is not used directly
for estimating model parameters. If the model over-fits the training
data, that is generalizes poorly to unseen examples, the held-out data
will have a high loss. However, it will also have a high loss if the
model under-fits, that is, performs poorly on all data. Held-out data
can therefore be used to find an optimal values for the regularizer
$\lambda$. Often, one tries several potential values and chooses the
one that minimizes the loss of the held-out data. Usually, one uses
the unregularized loss function for the held-out data.

\section{Machine Learning Experiments}

In this thesis and in the associated articles, I present several
experiments in morphological tagging. The experiments are conduct on
labeled data and follow a set pattern.

\begin{enumerate}
\item {\bf Data Splits} The labeled data set is divided into
  three non-overlapping parts: (1) a training set used for estimating
  model parameters (2) a development set used for setting hyper
  parameters and performing preliminary experiments during development
  and (3) a test sets which is used to perform the final evaluation of
  the model.
\item {\bf Feature Engineering} Using the training set and development
  set, a number of features are tested and depending on tagging errors
  in the development data, new features may be added.
\item {\bf Tuning} The model hyper-parameters are set using
  development data.
\item {\bf Training} When model parameters and hyper-parameters are
  set, the final model is trained on the combined training and
  development data. Training time is measured at this point.
\item {\bf Evaluation} The performance of the model is measured on the
  test data in order to derive an estimate of tagging accuracy and
  tagging speed.
\end{enumerate}

A crucial component of machine learning experiment is the {\it
  baseline}. For example, when investigating the impact of a set of
features on tagging accuracy, the baseline will be the model which
does not include those features. In Publication \ref{pub:6}, which
investigates the tagging accuracy, tagging speed or training speed of
the FinnPos toolkit, other established tagger tool-kits are used as
baseline.

When comparing tagging accuracy of two taggers, we compare their
accuracies on the test set. However, this is only an estimate of the
true tagging accuracies of the systems. When the difference in
performance between the systems is small, it is therefore not possible
to say with great certainty which system will perform better on new
data. In this situation, it is helpful to know about the variance of
the accuracy. 

The variance is a measure of the stability of the difference in
accuracies between tagging systems. It can be estimated using random
samples of the test data. If one system consistently performs better
than the other one on random samples of the test data, it is more
likely to performs better on some unseen sample. In contrast, when the
performance of one system is better on some samples and worse on
others, it is less certain that it would perform better on unseen data
even though it performs better on average in the entire test set.

Using statistical significance testing, the above comparison can be
formalized. In the papers included in this thesis, the 2-sided
Wilcoxon signed-rank test \citep{Wilcoxon45}. In contrast to the often
used t-test, the Wilcoxon test does not assume that the measurements
are drawn from a Gaussian distribution. A 2-sided test (instead of a
1-sided test) is used because it cannot be known which of the systems
actually has the higher accuracy although we know that one of the
systems performs better on the test set.\footnote{This was suggested
  by one of the reviewers of Publication \ref{pub:6}.}

