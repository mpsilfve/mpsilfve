\documentclass[b5paper]{article}

\usepackage{polyglossia}
\usepackage{fontspec}
\usepackage{xunicode}
\usepackage{xltxtra}
\usepackage{url}
\usepackage{hyperref}
\usepackage{expex}

\makeatletter
\def\blfootnote{\gdef\@thefnmark{}\@footnotetext}
\makeatother

\setmainfont[Mapping=tex-text]{Linux Libertine O}

\begin{document}

\title{Can Morphological Analyzers Improve the Quality of Optical Character Recognition?}

\author{Miikka Silfverberg\\
University of Helsinki\\
Dept. of Modern Languages\\
\\
\url{mpsilfve@iki.fi} \and
Jack Rueter\\
University of Helsinki\\
Dept. of Modern Languages\\
\\
\url{jack.rueter@helsinki.fi} 
}

\date{\today}

\maketitle

\begin{abstract}
\noindent Optical Character Recognition (OCR) can subtantially improve
  the usability of digitized documents. Language modelling using word
  lists is known to improve OCR quality for English. For
  morphologically rich languages, however, even large word lists do not reach
  high coverage on unseen text. Morphological analyzers offer a more
  sophisticated approach, which is useful in many language processing
  applications. This paper investigates language modelling in the
  open-source OCR engine Tesseract using morphological analyzers. We
  present experiments on two Uralic languages Finnish and
  Erzya. According to our experiments, word lists may still be
  superior to morphological analyzers in OCR even for languages with
  rich morphology. Our error analysis indicates that morphological
  analyzers can cause a large amount of real word OCR errors.
\end{abstract}

\section{Introduction}

Digital media is an integral part of modern society. Thus digitization
of printed matter is crucial for the viability of minority languages. It
also serves the linguistic community by making printed media widely
available. Simply scanning documents, however, is not enough because
few applications can deal with images directly. {\it Optical Character
  Recognition} (OCR) can subtantially improve the usability of
digitized documents for example by allowing search engines to index
them. In this paper, we investigate improving the quality of OCR for
{\it languages with rich morphology}, that is languages with extensive
inflection, derivation and compounding.

OCR engines can benefit from language modelling, which is a field
encompassing a variety of techniques that aim at improving the
function of language processing applications by capturing key
properties of the target language. For example, translation software
and speech recognizers benefit greatly from sophisticated statistical
language models. In OCR, however, simple language models such as word
lists are commonly used.

Word lists are adequate in applications designed for languages with
limited morphology such as English. Nevertheless, morphologically rich
languages, including the Uralic languages, require more elaborate
approaches. For these languages, even extensive word lists are
unlikely to reach high coverage on previously unseen text \cite{creutz07}.

In contrast to word lists, {\it morphological analyzers}
\cite{koskenniemi83}, which encode the derivational and inflectional
morphology of a language, can achieve substantially higher
coverage. Thus it is conceivable that language models utilizing
morphological analyzers could improve the quality of OCR for
morphologically rich languages.

In this paper, we present experiments on OCR for two Uralic languages
with rich morphology, Finnish and Erzya. We performed the experiments
using the open-source OCR engine Tesseract \cite{smith07} and
open-source morphological analyzers for both languages. As baselines,
we use both OCR systems without language modeling and systems using
word lists.

In light of our experiments, it seems that morphological analyzers do
help in OCR of morphologically rich languages compared to a baseline
without language modelling. We were, however, unable to get improvements
over using word lists harvested from the Wikipedia databases for Erzya
and Finnish. This result is somewhat surprising, as the morphological
analyzers have higher coverage on the test material than the word
lists do. Error analysis revealed that the high coverage of the
morphological analyzers may in fact present a problem for the OCR
process, as it leads to a substantial number of real word errors.

Although we did not get improvements over word lists, it is worth
pointing out that for some under-resourced minority languages
morphological analyzers created by linguists represent the best
readily available lexical resources in machine readable format. The
reason for this is that digital content on the Internet can be scarce
and the orthography of the material may be non-standard. Therefore,
using a morphological analyzer as part of an OCR engine can still be
motivated.

The paper is structured as follows. We describe related work in
Section \ref{rel}. In Section \ref{met}, we describe the Tesseract OCR
engine, morphological analyzers and their integration. Section
\ref{exp} details the experimental setup. In Section \ref{res}, we
present the results of the experiments and a brief error analysis for
the experiment on Finnish. We conclude the paper in Section
\ref{disc}.

\section{Related Work}
\label{rel}
Although, morphological analyzers have been used in OCR {\it
  post-processing}, this is, to our knowledge, the first investigation
of utilizing morphological analyzers as language models {\it during}
the OCR process. There are, however, other approaches to language
modeling for OCR of morphologically rich languages, which have been
investigated.

Smith et. al \cite{smith09} add a module, which expands the vocabulary
by generating additional word forms from stem suffix pairs. In
contrast to our approach, their method requires no additional
linguistic resources, since the sets of stems and affixes are
harvested from word lists. We believe, however, that this approach is
unlikely to work well with languages that have extensive compounding
such as Finnish. Data sparseness will be a grave problem.

There is a large body of literature on spelling correction for
morphologically rich languages, for example \cite{oflazer94} and
\cite{pirinen12}, and similar approaches have been successfully
applied to OCR post-processing, for example
\cite{Takeuchi2000,Proszeky2014,Magdy2006}. In our work, we wanted to
improve the language model instead of using post-processing to correct
errors, because post-processing cannot in principle give as good
results as improved language modeling. The reason is that knowledge
about the reliability of predictions of the individual characters has
already been lost before the post-processing stage.\footnote{If this
  knowledge were available at the post-processing stage,
  post-processing could probably be used to the same effect as
  language modeling.}

Finally, character based statistical language models have been
investigated, but the results of this approach are mixed
\cite{smith11}. It seems that statistical language models do improve
performance when the baseline is low, but they may in fact degrade
the performance of high accuracy OCR systems. Statistical
language modeling, however, has given good results in the related field of
handwritten text recognition \cite{marti01}, where the overall
performance is much lower.

\section{Methods}
\label{met} In this section, we describe the Tesseract OCR engine, the
HFST finite-state library, HFST morphological analyzers, and the
process of combining these utilities.

\subsection{Tesseract}
The Tesseract\footnote{https://code.google.com/p/tesseract-ocr/} OCR
engine \cite{smith07} was originally developed at HP Labs between 1984
and 1995 for high quality OCR of English. In 2005 it was released as
an open-source project and has since been applied to several languages
and alphabets, for example Finnish. Tesseract was therefore a natural
starting point for exploring improvements for OCR of the Uralic languages.

The recognition process of Tesseract can be seen as a pipeline
consisting of four stages \cite{smith07}: (1) identification of
character boundaries, (2) grouping of characters into words and lines,
(3) word level recognition, and (4) resolution of ambiguous word
spacing.

Our work focuses on the third stage of the pipeline, namely word level
recognition. Word level recognition encompasses two sub-tasks: character
recognition using a character classifier and word recognition using a
combination of an additional word level classifier and various
language models. During word level recognition, the word level classifier
and language models give competing suggestions based on the output of
the character recognizer. 
%These suggestions are weighted using
%heuristic, model specific, weights and the highest scoring suggestion
%becomes the final OCR output word.
The highest scoring suggestion becomes the OCR output.% word.

The existing language models in Tesseract are word lists, which are
compiled into {\it directed acyclic graphs} (DAG) for fast
processing. Tesseract incorporates a number of different language
models\footnote{https://code.google.com/p/tesseract-ocr/wiki/TrainingTesseract3},
for example: A short list of {\it frequent word forms}, a more
extensive {\it dictionary}, {\it punctuation patterns} and a list of
{\it word forms containing digits}.

Each language model and the adaptive classifier have associated
weights which determine their relative importance. For example the
frequent word model has a greater weight than the dictionary
model reflecting the higher prior for seeing frequent words.

When the character model returns a scored set of possible word forms,
each of the language models and the word level classifier return the
highest scoring word form known to the model. These suggestions are
further re-scored using the model specific weights. Finally, the highest
scoring suggestion is selected.

We modify this system by replacing the word lists with a morphological
analyzer. The associated weight for the analyzer was the same as for
the dictionary model in the original system.

\subsection{Helsinki Finite-State Technology}
Helsinki Finite-State Technology (HFST) \cite{linden13} is an
open-source C++ library and collection of tools for constructing
finite-state transducers and morphological analyzers based on
finite-state technology. Morphological analyzers compatible with the
HFST library exist for several languages. We know of at least fifteen
Uralic languages\footnote{http://giellatekno.uit.no/all-lang.eng.html}
with HFST morphological analyzers, for example Erzya and Finnish.

\subsection{Morphological Analyzers as OCR Language Models}
As mentioned above, Tesseract internally represents language models as
directed acyclic graphs or DAGs. HFST morphological analyzers are
finite-state transducers (FST), which are closely related to DAGs. The
main difference is that finite-state transducers transform strings
instead of simply accepting or discarding them. Additionally,
finite-state transducers can be cyclic unlike DAGs. By modifying both
Tesseract and the analyzers, we were able integrate morphological
analyzers into Tesseract.

There exists a straight-forward conversion ({\it projection})
from FSTs to finite-state automata, which are identical to DAGs in
other respects, but may be cyclic like FSTs. 

It turned out, that Tesseract is not in principle incompatible with
cyclic graphs. The existing implementation simply did not offer a way
to produce cyclic graphs. Fortunately, it was not difficult to
implement a sub-class for the Tesseract language model class, {\tt
  Dawg}, which does support cyclic graphs. Additionally, we implemented a
driver for HFST transducers in optimized lookup format, which supports
lookup speeds of up to 100 000 words/s \cite{silfverberg09}.

HFST morphological analyzers can contain so called flag diacritics
\cite{beesley03}, which are used to compress the finite-state machine
by introducing non-determinism in a controlled way. Tesseract employs
a search algorithm for finding word suggestions that requires that
the language model be deterministic. Hence, it cannot handle flag
diacritics. Fortunately, HFST includes utilities which can be used to
eliminate flag diacritics from a finite-state machine without
changing its behaviour.

All the necessary steps to transform an HFST morphological analyzer
into a Tesseract language model have been incorporated into the HFST
interface as the tool\\{\tt hfst-fst2tesseract}.

\section{Experiments}
\label{exp}

In this section we describe the Finnish and Erzya data sets used in
the experiments, the evaluation procedure and the experiments.

\subsection{Data}
We evaluate the impact of morphological analyzers in OCR for two
Uralic languages, Erzya and Finnish. 
The Erzya language has a relatively rich morphological system of
regular inflection, most extensive in the verbs and nouns. The verbs
attest to object and subject conjugation in 7 moods, whereas there are
9 declensions for 9-15 regular case forms in nouns, with additional
conjugation possibilities in two tenses for 3-6 of those. Erzya is
written using the Cyrillic alphabet.
Finnish is similar to Erzya in that it has a extensive noun and verb
inflection. Additionally, Finnish has a productive compounding
mechanism, which gives rise to an extensive vocabulary. Unlike Erzya,
Finnish is written using the Latin alphabet.

We perform experiments on excerpts from novels.
For Finnish, we use pages 5 - 21 of the novel {\it Elokuu} (August) by
F.E. Sillanp\"{a}\"{a} \cite{sillanpaa08} (3219 tokens, 24096
characters) and for Erzya, we use pages 3 - 21 from the translation of
the, originally Russian, novel {\it Ава} (Mother) by Maksim Gorky
\cite{gorki} (4539 tokens, 58548 characters). In order to estimate the
effect of different language models on scanned material of varying
quality, the data were scanned in different resolutions: 100, 200 and
300 dpi.

Even without language modelling, Tesseract performs quite well on
scanned images of quality 300 dpi. The result requires relatively
little manual correction. In contrast, 100 dpi images usually result
in quite poor performance. In fact, manual correction may take
longer than simply writing the text from scratch.

\subsection{Resources}
For constructing Tesseract systems with word lists as language models,
we used the XML dumps of the
Erzya\footnote{\url{ftp://wikipedia.c3sl.ufpr.br/wikipedia/myvwiki/20140927/myvwiki-20140927-pages-meta-current.xml.bz2}}
and
Finnish\footnote{\url{ftp://wikipedia.c3sl.ufpr.br/wikipedia/fiwiki/20141018/fiwiki-20141018-pages-meta-current.xml.bz2}}
Wikipedias. We used the utility {\tt
  wp2text}~\footnote{\url{https://github.com/yohasebe/wp2txt}} for
extracting the text contents from the XML files.

We formed lists containing the N most frequent word forms for various
N in the range 1000 up to 1 million for Finnish and 1000 up to 68 000
for Erzya (there were no more unique word forms in the Erzya
Wikipedia).
 
In addition to Wikipedia text, we used freely available morphological
analyzers for Finnish and Erzya. OMorFi \cite{pirinen11} is a broad
coverage Finnish morphological analyzer available
online\footnote{\url{https://code.google.com/p/omorfi/}}. For Erzya,
we used the Erzyan analyzer distributed by the Giellatekno project
\cite{moshagen14}.

The coverages of different linguistic resources on test data are shown
in Table \ref{fin-myv-coverage}. For both languages, the coverage is
best using the morphological analyzer. However, for Finnish, the
coverage of the one million word list comes very close.

\begin{table}[!htb]
\begin{center}
\begin{tabular}{lr}
\hline 
Erzya                   & Coverage  \\
\hline 
1K word list            &   28.0\%  \\
10K word list           &   49.5\%  \\
68K word list           &   58.6\%  \\
Morphological analyser  &   80.6\%  \\
                        &
\end{tabular}
\quad
\begin{tabular}{lr}
\hline 
Finnish                 & Coverage \\
\hline 
1K word list            &  32.2\% \\
10K word list           &  52.8\% \\
100K word list          &  71.4\% \\
1000K word list         &  84.5\% \\
Morphological analyser  &  86.7\% 
\end{tabular}
\caption{Coverages of linguistic resources on the text tokens of the Erzyan and Finnish test
  material.}\label{fin-myv-coverage}
\end{center}
\end{table}

\subsection{Experiments}
We trained five different OCR systems for Finnish and four systems for Erzya:
\begin{itemize}
\item A system without a language model (the baseline).
\item Systems using 1000 and 10 000 word vocabularies both for Finnish
  and Erzya, a 68 000 word system for Erzya and 100 000 and 1 million
  word systems for Finnish.
\item A system using a morphological analyzer as language model.
\end{itemize}

For Finnish, we constructed the baseline system simply by deleting the
vocabularies ({\tt freq-dawg} and {\tt word-dawg}) from the existing
Tesseract OCR system for Finnish~\footnote{see:
  \url{https://code.google.com/p/tesseract-ocr/downloads/list}}. For
Erzya, we trained our own baseline system.

In order to compile systems with vocabularies ranging from 1000 words
to 1 million words, we extracted the most common N words from the
Wikipedia, compiled them into a directed acyclic graph using the
Tesseract utility {\tt wordlist2dawg} and used the graphs as word
models ({\tt word-dawg}) in a system which otherwise was identical to
the baseline system.

The morphological analyzers, were first processed using the HFST
utility\\{\tt hfst-fst2tesseract}. We then combined them with a system
identical to the baseline systems. 

\subsection{Evaluation}
It is tempting to view OCR as a special case of sequence labeling,
since an OCR engine essentially labels the characters in a digitized
text using alphabetical symbols. This suggest
evaluation based on character error rate in relation to a gold
standard text.

Unfortunately, simple metrics such as character error rate cannot be
used, since OCR frequently changes the length of the underlying text,
because spurious characters may be inserted and characters in the text
may be deleted. Therefore, we evaluated by measuring the {\it edit
  distance} \cite{levenshtein66} of the OCR result and the gold
standard.

In practice, we first aligned the texts on character level using the
Unix utility {\tt diff}. We then computed the number of edits required
to transform the OCR result into the gold standard text. We call this
figure the {\it edit count} (EC). For each experiment, we report both
raw edit counts and the reduction in edit count (ER) compared to the
baseline OCR system without language modeling.

The edit reduction, ER, from a baseline $B$ to an improved edit
count $C$ is
$${\rm ER} = \frac{B - C}{B}$$
If, the baseline $B$ is in fact better than the count $C$, ER will be
be negative.

We divided the test material into pages, and performed paired one
sided Wilcoxon tests to asses the statistical significance of our
results with confidence level 95\%. We compared all systems to
the baseline model. We additionally compared the best word-list system
to the system using a morphological analyzer.

\section{Results}
\label{res}
In this section we show the results for Finnish in Table
\ref{fin-novel-res} and for Erzya in Table
\ref{myv-novel-res}. 

For the Finnish novel, all systems utilizing some kind of language
modelling fared better than the baseline system without any kind of
vocabulary information. The morphological analyzer performed better
than the other systems on the lowest image quality 100 dpi. Otherwise,
it in fact performed worse than the other systems utilizing language
modelling.

For resolutions 300 and 200 dpi, all language models gave
statistically significant improvements over the baseline in the 95\%
confidence interval. The best word list system was better than the
morphological analyzer. For 100 dpi, only the morphological analyzer
performed significantly better than the baseline, but not
significantly better than the best word list model.

\begin{table}[!htb]
\begin{center}
\begin{tabular}{lrrr}
\hline 
                  & 300 dpi & 200 dpi & 100 dpi \\
\hline 
No language model & ~0.0\% (794)          & ~0.0\% (1265)          & 0.0\% (15504)  \\
1000 words        & ~32.1\% (539)  & ~36.8\% (799)        & 2.1\% (15172)           \\
10 000 words      & {\bf ~35.3}\% (514)  & ~44.7\%  (699)  & 4.0\% (14891)          \\
100 000 words     & ~31.5\% (544)   & ~44.0\%  (708)  & 3.2\%  (15014)              \\
1 million words   & ~33.5\% (528)   & {\bf ~45.4\%} (691)  & 2.4\% (15131)          \\
Morph. analyzer   & ~25.3\% (593)    & ~30.0\% (885)     & {\bf 5.7\%} (14621)      \\
\hline 
\end{tabular}
\caption{Edit reduction (and total edit count) for the Finnish novel Elokuu using different systems and resolutions.}\label{fin-novel-res}
\end{center}
\end{table}

The results for Erzya paralleled those of Finnish. The morphological
analyzer improves over the word lists only for the lowest resolution
100 dpi. For resolution 200 dpi, the morphological analyzer does not
seem to have any effect. For 200 and 300 dpi, the morphological
analyzer was significantly worse than the best word list model. For
100 dpi, the model with 1000 word vocabulary was significantly worse
than the baseline, but the other results were not statistically
significant.

\begin{table}[!htb]
\begin{center}
\begin{tabular}{lrrr}
\hline 
                  & 300 dpi & 200 dpi & 100 dpi \\
\hline 
No language model &  0.0\% (3257)  &  0.0\% (3224)  &  0.0\% (15788)  \\
1000 words        &  20.9\% (2576)  &  11.7\% (2846)  & -10.7\%  (17473) \\
10 000 words      &  29.5\% (2295)  &   {\bf 22.7\%} (2492)  & 1.8\% (15498)  \\
68K words         &  {\bf 30.9\%} (2249)  &  21.9\% (2517)  & 0.5\% (15702)\\
Morph. analyzer   &  8.0\% (2996)  &  -0.1\% (3230)  & {\bf 2.8\%} (15353)  \\
\hline 
\end{tabular}
\caption{LER for the Erzyan novel Ава using different systems and resolutions.}\label{myv-novel-res}
\end{center}
\end{table}

\subsection{Error Analysis}

We examined the errors of the Finnish OCR system using a morphological
analyzer and the best performing word list system for the highest
image quality 300 dpi.

We classified errors into two types: real word errors and others. Real
word errors are errors, where the resulting incorrect word is known by
the language model, for example a genitive of
'his/her' ``Hänen'' was recognized erroneously as the genitive
of 'pike' ``Hauen''. Other errors simply encompass all other error
types, common examples include insertion and deletion of punctuation
and casing errors such as lower case ``v'' being recognized as an
upper case ``V'' and vice versa.

A total of 18\% of the errors produced by the morphological analyzer
were real word errors. In contrast the word list only gave 2\% real
word errors.

\section{Discussion and Conclusions}
\label{disc}

In light of our experiments, it seems that morphological analyzers may
do more harm than good in OCR. For higher resolutions, 200 and 300 dpi,
the morphological analyzers fared worse than even the smallest
vocabulary of 1000 words. This happens both for Finnish and Erzya. We
believe, the large amount of real word errors is to blame. However,
for the lowest image quality 100 dpi, the morphological analyzers do
improve performance. It is interesting to compare these results to
statistical language modelling for OCR, which also improves results
when performance is low, but can degrade it otherwise \cite{smith11}.

Interestingly, vocabulary size does not seem to be a very good
predictor of performance. For Finnish, the 10 000 word vocabulary
performs best on the 300 dpi material with. Similarly, the system with
10 000 word vocabulary performs best for Erzya material in 200 dpi
resolution. Overall, the results for all but the smallest vocabularies
lie very close to each other.

It would seem that the effect of language modelling is already
exhausted at 10 000 words. Therefore, it is not horribly surprising
that the morphological analyzer does not achieve better results than
the systems using word lists. The fact that its performance
is so low, however, was mildly surprising.

In order to limit the number of real word errors, we tried excluding
all compounds that had not been attested in real text from the
morphological analyzers. Unfortunately, this did not improve the
results.

It might be worth while trying to include word frequency information into
the language model. However, this remains future work, as it would
require extensive changes to Tesseract.

\section*{Acknowledgments}
We, the authors, want to thank Jussi-Pekka Hakkarainen, Timo Honkela
and Krister Lind\'{e}n for helpful ideas. We also want to thank Tommi
Pirinen for creating OMorFi and the HFST team for maintaining the HFST
toolkit. Additionally, we want to thank the KONE foundation for
funding this research. Finally, all three anonymous reviewers made
great suggestions for improvement and pointed out related
work. We are in your debt!

\bibliographystyle{unsrt}
\bibliography{fiwclul2015}

\end{document}

